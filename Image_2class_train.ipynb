{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码和4class相似，可以参考4class那份代码相关的备注\n",
    "ENV = \"Meg\"\n",
    "datadir = '/home/megstudio/workspace/competedata'\n",
    "libdir = '/home/megstudio/workspace/archive/lib'\n",
    "outputdir = '/home/megstudio/workspace'\n",
    "otherdir = '/home/megstudio/workspace/archive'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(f\"{libdir}/timm_effnetv2\")\n",
    "os.environ['TORCH_HOME']='workspace/archive/torch_cache/'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import timm\n",
    "from warnings import filterwarnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import glob\n",
    "from torch.nn import DataParallel\n",
    "from collections import OrderedDict\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "filterwarnings(\"ignore\")\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，以便实验复现\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # set True to be faster\n",
    "seed_everything(42) \n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"  \n",
    "    \n",
    "    \n",
    "def init_logger(log_file=outputdir+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger(f'{outputdir}/train.log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数和模型超参数\n",
    "class CFG:\n",
    "    train_bs = 32 # 训练集batch_size，请根据GPU性能调整\n",
    "    valid_bs = 64 # 验证集batch_size，请根据GPU性能调整\n",
    "    n_worker = 24 # 数据导入线程数，请根据CPU性能调整\n",
    "    gpu_parallel= True # 是否启用多个GPU，请根据GPU性能调整\n",
    "\n",
    "    suffix = \"9999\" # 本次实验id\n",
    "    fold_id = [0,1,2,3,4]\n",
    "    image_size = 512 # 图片尺寸\n",
    "    model_arch = \"tf_efficientnetv2_l_21k\" # tf_efficientnetv2_m, tf_efficientnetv2_l_21k  tf_efficientnetv2_l\n",
    "    n_epochs = 9\n",
    "    max_early_stop = 3\n",
    "\n",
    "    loss_fn = trial.suggest_categorical(\"loss_fn\", [\"FocalLoss\"])\n",
    "    focal_alpha = 0.4\n",
    "    focal_gamma = 2.8\n",
    "    loss_aux = \"binary_cross_entropy\"\n",
    "    loss1_coef = 1.5\n",
    "    optimizer = \"AdamW\"\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    scheduler_warmup = None\n",
    "    warmup_epo = 1\n",
    "    warmup_factor = 15\n",
    "\n",
    "    T_max= n_epochs-warmup_epo-1 if scheduler_warmup==\"GradualWarmupSchedulerV3\" else n_epochs-1\n",
    "    \n",
    "    init_lr = 3.406892e-4\n",
    "    min_lr = 2.756527e-7\n",
    "    weight_decay = 4.872415e-4\n",
    "    drop_rate = 0.35\n",
    "    drop_path_rate = 0.2\n",
    "    \n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = pd.read_csv(f\"{datadir}/train_image_level.csv\")\n",
    "train_study = pd.read_csv(f\"{datadir}/train_study_level.csv\")\n",
    "TRAIN_DIR = f\"{datadir}/train{CFG.image_size}png/train\"\n",
    "\n",
    "train_unique_study_image = pd.DataFrame([],columns=[\"id\",\"boxes\",\"label\",\"StudyInstanceUID\"])\n",
    "\n",
    "old_study_list = []\n",
    "old_boxes_list = []\n",
    "cnt = 0\n",
    "for idx, image_id, boxes, df_label, StudyInstanceUID in train_image.itertuples():\n",
    "    if StudyInstanceUID not in old_study_list:\n",
    "        old_study_list.append(StudyInstanceUID)\n",
    "        if df_label != \"none 1 0 0 1 1\":\n",
    "            old_boxes_list.append(StudyInstanceUID)\n",
    "        train_unique_study_image = train_unique_study_image.append(pd.DataFrame([[image_id, boxes, df_label, StudyInstanceUID]], columns=[\"id\",\"boxes\",\"label\",\"StudyInstanceUID\"]))\n",
    "    else:    \n",
    "        if StudyInstanceUID in old_boxes_list:\n",
    "            continue\n",
    "        else: # StudyInstanceUID not in old_boxes_list\n",
    "            if df_label != \"none 1 0 0 1 1\":\n",
    "                old_boxes_list.append(StudyInstanceUID)\n",
    "                train_unique_study_image.loc[train_unique_study_image[\"StudyInstanceUID\"] == StudyInstanceUID,[\"id\",\"boxes\",\"label\",\"StudyInstanceUID\"]] = [image_id, boxes, df_label, StudyInstanceUID]\n",
    "\n",
    "train_unique_study_image = train_unique_study_image[[\"StudyInstanceUID\",\"id\"]].reset_index(drop=True)\n",
    "# train_unique_study_image = train_unique_study_image[[\"StudyInstanceUID\",\"id\",\"label\"]].reset_index(drop=True)\n",
    "\n",
    "# train_unique_study_image = train_image.groupby(\"StudyInstanceUID\").first()[\"id\"].reset_index()\n",
    "train_study['StudyInstanceUID'] = train_study['id'].apply(lambda x: x.replace('_study', ''))\n",
    "df_train = train_study.merge(train_unique_study_image, on='StudyInstanceUID')\n",
    "# Make a path folder\n",
    "df_train['file_path'] = df_train[\"id_y\"].apply(lambda x:TRAIN_DIR + \"/\" + x.replace(\"_image\",\"\") + \".png\")\n",
    "df_train = df_train.drop(['id_x', 'id_y'], axis=1)\n",
    "df_train.head()\n",
    "\n",
    "# 做5fold切分数据，并把每行归属的fold加入到df_train中\n",
    "gkf = GroupKFold(n_splits=5) \n",
    "df_train['fold'] = -1\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf.split(df_train, groups = df_train.StudyInstanceUID.tolist())):\n",
    "    df_train.loc[valid_idx, 'fold'] = fold\n",
    "df_train[\"label_2class\"] = (df_train[\"Negative for Pneumonia\"] - 1 )*-1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, CLAHE, RandomRotate90,\n",
    "    Transpose, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n",
    "    CenterCrop, Resize, RandomCrop, GaussianBlur, JpegCompression, Downscale, ElasticTransform, ImageCompression\n",
    ")\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "augs = {\n",
    "    \"HorizontalFlip_p\": 0.5,\n",
    "    \"ShiftScaleRotate_p\": 0.5,\n",
    "    \"shift_limit\": 0.06,\n",
    "    \"scale_limit\": 0.4,\n",
    "    \"rotate_limit\": 70,\n",
    "    \"Cutout_p\": 0.4,\n",
    "    \"num_holes\": 5,\n",
    "    \"max_hw_size\": 0.08,\n",
    "\n",
    "    \"RandomBrightnessContrast_p\": 0.1,\n",
    "    \"brightness_limit\": 0.5   ,\n",
    "    \"contrast_limit\": 0.5     ,\n",
    "    \"HueSaturationValue_p\": 0.5,\n",
    "    \"hue_shift_limit\": 40,\n",
    "    \"sat_shift_limit\": 40    ,\n",
    "    \"val_shift_limit\": 20,\n",
    "}\n",
    "\n",
    "transforms_train = Compose([\n",
    "            RandomCrop(CFG.image_size, CFG.image_size),\n",
    "            HorizontalFlip(p=augs[\"HorizontalFlip_p\"]), \n",
    "            ShiftScaleRotate(p=augs[\"ShiftScaleRotate_p\"], shift_limit=augs[\"shift_limit\"], scale_limit=augs[\"scale_limit\"], rotate_limit=augs[\"rotate_limit\"]), \n",
    "            Cutout(p=augs[\"Cutout_p\"], num_holes=augs[\"num_holes\"], max_h_size=int(CFG.image_size*augs[\"max_hw_size\"]), max_w_size=int(CFG.image_size*augs[\"max_hw_size\"])),      \n",
    "            ],\n",
    "            additional_targets={'image0': 'image'})\n",
    "\n",
    "transforms_train_nomask = Compose([\n",
    "            RandomBrightnessContrast(p=augs[\"RandomBrightnessContrast_p\"], brightness_limit=augs[\"brightness_limit\"], contrast_limit=augs[\"contrast_limit\"]),\n",
    "            HueSaturationValue(p=augs[\"HueSaturationValue_p\"], hue_shift_limit=augs[\"hue_shift_limit\"], sat_shift_limit=augs[\"sat_shift_limit\"], val_shift_limit=augs[\"val_shift_limit\"]),     \n",
    "            Normalize() \n",
    "            ],)\n",
    "\n",
    "transforms_valid = Compose([\n",
    "    Resize(CFG.image_size, CFG.image_size),\n",
    "    Normalize() \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIIMDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode # 数据集模式（train模式或test模式）\n",
    "        self.transform = transform # 数据增强\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) # 获取dataframe行数\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index] # 获取指定（index）行\n",
    "        img = cv2.imread(row.file_path) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            mask_img = cv2.imread(row.file_path.replace(\"rsna512png\", \"rsna512png_mask\").replace(\"train512png\", \"train512png_mask\"))\n",
    "            mask_img = cv2.cvtColor(mask_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 如果有数据增强，则做数据增强\n",
    "        if self.transform is not None: \n",
    "            if self.mode == \"train\":\n",
    "                transform_img  = self.transform(image=img, image0=mask_img)\n",
    "                img = transforms_train_nomask(image=transform_img['image'])[\"image\"]\n",
    "                mask_img = transform_img['image0']\n",
    "                mask_img = mask_img.transpose(2,0,1).astype(np.float32)\n",
    "                mask_img = mask_img/255\n",
    "            else:\n",
    "                img = self.transform(image=img)[\"image\"]\n",
    "                \n",
    "        # 调整一下数据格式\n",
    "        img = img.transpose(2,0,1).astype(np.float32)\n",
    "        # img = img/255; \n",
    "\n",
    "        # 返回 获取到的图片\n",
    "        if self.mode == 'train':\n",
    "            return torch.tensor(img).float(), torch.tensor(mask_img).float(), torch.tensor(row[['label_2class']]).float()\n",
    "        elif self.mode == 'valid':\n",
    "            return torch.tensor(img).float(), torch.tensor(row[['label_2class']]).float()\n",
    "        elif self.mode == 'test':\n",
    "            return torch.tensor(img).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=1, model_arch=CFG.model_arch, pretrained=True):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        e = timm.create_model(model_arch, pretrained=pretrained, drop_rate=CFG.drop_rate, drop_path_rate=CFG.drop_path_rate)\n",
    "        \n",
    "        self.logit = nn.Linear(e.classifier.in_features, num_classes)\n",
    "        self.e1 = nn.Sequential(e.conv_stem, e.bn1, e.act1,)\n",
    "        \n",
    "        self.b0 = e.blocks[0]\n",
    "        self.b1 = e.blocks[1]\n",
    "        self.b2 = e.blocks[2]\n",
    "        self.b3 = e.blocks[3]\n",
    "        self.b4 = e.blocks[4] # channel = 224\n",
    "        self.b5 = e.blocks[5]\n",
    "        self.b6 = e.blocks[6]\n",
    "        \n",
    "        self.mask = nn.Sequential(\n",
    "            nn.Conv2d(224, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.e2 = nn.Sequential(e.conv_head, e.bn2, e.act2,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "        x = self.e1(x)\n",
    "        x = self.b0(x)\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        # ==========================\n",
    "        mask = self.mask(x)\n",
    "        # ==========================\n",
    "        x = self.b5(x)\n",
    "        x = self.b6(x)\n",
    "        x = self.e2(x)\n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        logit = self.logit(x)\n",
    "\n",
    "        return logit, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler = GradScaler()\n",
    "def train_func(train_loader):\n",
    "    model.train() # 模型调整到训练模式\n",
    "    losses = []; loss0_list = []; loss1_list = [];\n",
    "    for images, truth_mask, targets in train_loader: # 从数据管道中导入 图片和标签\n",
    "        images, truth_mask, targets = images.to(device).float(), truth_mask.to(device), targets.to(device).float()\n",
    "        truth_mask = truth_mask[:,0:1,:,:] \n",
    "        truth_mask = F.interpolate(truth_mask, size=(32,32), mode='bilinear', align_corners=False)\n",
    "\n",
    "        with autocast():\n",
    "            logits, mask  = model(images) # 把数据放入模型训练\n",
    "            # loss0\n",
    "            if CFG.loss_fn == \"CrossEntropyLoss\":\n",
    "                targets = targets.argmax(-1)\n",
    "            loss0 = criterion(logits, targets)\n",
    "            # loss1\n",
    "            if CFG.loss_aux == \"binary_cross_entropy\":\n",
    "                loss1 = F.binary_cross_entropy_with_logits(mask, truth_mask)\n",
    "            loss1 = loss1*CFG.loss1_coef\n",
    "            scaler.scale(loss0+loss1).backward() \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        losses.append(loss0.item()+loss1.item()); loss0_list.append(loss0.item()); loss1_list.append(loss1.item())\n",
    "\n",
    "    return np.mean(losses), np.mean(loss0_list), np.mean(loss1_list), optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证函数\n",
    "def valid_func(valid_loader):\n",
    "    model.eval() # 模型调整到评估模式\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        all_valid_labels = []\n",
    "        all_valid_preds = []\n",
    "        for images, targets in valid_loader: # 从数据管道中导入 图片和标签\n",
    "            images, targets = images.to(device).float(), targets.to(device).float() # 将数据放入GPU\n",
    "            logits, mask = model(images) # 把数据放入模型获得features\n",
    "\n",
    "            # logits = F.softmax(logits,-1)\n",
    "            if CFG.loss_fn == \"CrossEntropyLoss\": \n",
    "                loss = criterion(logits, targets.argmax(-1))\n",
    "            else:\n",
    "                loss = criterion(logits, targets) # 计算loss\n",
    "                \n",
    "            # print(\"valid loss:\")\n",
    "            # print(loss)    \n",
    "                \n",
    "            losses.append(loss.item()) # 存下当前的loss\n",
    "            smooth_loss = np.mean(losses[-30:]) # 求近30步的平均loss\n",
    "\n",
    "            all_valid_labels += [targets.detach().cpu().numpy()]\n",
    "            all_valid_preds += [logits.detach().cpu().numpy()]\n",
    "\n",
    "        loss_valid = np.mean(losses) # 求全体平均loss\n",
    "        all_valid_labels = np.concatenate(all_valid_labels)\n",
    "        all_valid_preds = np.concatenate(all_valid_preds)\n",
    "        all_valid_labels_argmax = all_valid_labels.argmax(-1)\n",
    "        class_map = []\n",
    "        for i in range(1):\n",
    "            class_map.append(average_precision_score(all_valid_labels_argmax==i, all_valid_preds[:,i]))\n",
    "\n",
    "        valid_map_score = average_precision_score(all_valid_labels, all_valid_preds)\n",
    "        v_map_066 = valid_map_score*2/3\n",
    "    return loss_valid, valid_map_score, class_map, model # 返回全体平均loss 和 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=CFG.focal_alpha, gamma=CFG.focal_gamma, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.BCEWithLogitsLoss()(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "# 自定义一个scheduler(优化器的调度器)\n",
    "class GradualWarmupSchedulerV3(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV3, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(pick_params_d)\n",
    "LOGGER.info(pick_params_d)\n",
    "for n_fold in range(5):\n",
    "    if n_fold not in CFG.fold_id:\n",
    "        continue\n",
    "    LOGGER.info(f'     |------ {CFG.suffix} -- fold{n_fold} -- TRAIN ------|----------------------------- VALID --------------------------|--------')\n",
    "    LOGGER.info(f'epoch| lr           loss    loss0   loss1 | loss    mAP      mAP*2/3  2class_mAP |  time  ')\n",
    "    #            ' 01  | 0.00000010   0.364   0.609   0.609 | 0.609   0.5612   0.3705   0.5216     |  02:30 '\n",
    "\n",
    "\n",
    "    # 创建模型\n",
    "    model = EfficientNetModel()\n",
    "    if CFG.gpu_parallel: # 根据配置决定是否启用多GPU\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        model = DataParallel(model, device_ids=range(num_gpu))\n",
    "    model.to(device)\n",
    "    \n",
    "    # 创建损失函数\n",
    "    if CFG.loss_fn == \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss() \n",
    "    elif CFG.loss_fn == \"CustomLoss\":\n",
    "        criterion = CustomLoss(weights=CFG.loss_weights)\n",
    "    elif CFG.loss_fn == \"FocalLoss\":\n",
    "        criterion = FocalLoss()\n",
    "    elif CFG.loss_fn == \"CrossEntropyLoss\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    # 创建优化器\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=CFG.init_lr/CFG.warmup_factor if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV3\"] else CFG.init_lr,\n",
    "                      weight_decay=CFG.weight_decay)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr) # 创建调度器\n",
    "\n",
    "    # 创建升温调度器\n",
    "    if CFG.scheduler_warmup==\"GradualWarmupSchedulerV3\":\n",
    "        scheduler_warmup = GradualWarmupSchedulerV3(optimizer, multiplier=CFG.warmup_factor, total_epoch=CFG.warmup_epo, after_scheduler=scheduler)\n",
    "\n",
    "    df_train_this = df_train[df_train['fold'] != n_fold] # 将不是fold_id部分的数据作为训练数据\n",
    "    df_valid_this = df_train[df_train['fold'] == n_fold] # 将fold_id部分的数据作为验证数据\n",
    "\n",
    "    dataset_train = SIIMDataset(df_train_this, 'train', transform = transforms_train) # 创建训练数据集\n",
    "    dataset_valid = SIIMDataset(df_valid_this, 'valid', transform = transforms_valid) # 创建验证数据集\n",
    "\n",
    "    # 创建训练/验证数据集对应的数据管道\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=CFG.train_bs, shuffle=True, num_workers = CFG.n_worker, drop_last=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=CFG.valid_bs, shuffle=False, num_workers = CFG.n_worker, drop_last=False)\n",
    "\n",
    "    best_valid_map = 0\n",
    "    best_epoch = 0\n",
    "    early_stop_num = 0\n",
    "    early_stop = False\n",
    "    for epoch in range(CFG.n_epochs): # epoch循环\n",
    "        start_time = time.time()\n",
    "        early_stop_num += 1\n",
    "        losses_mean, loss0_list_mean, loss1_list_mean, lr_value = train_func(train_loader)\n",
    "        loss_valid, valid_map_score, class_map, op_model = valid_func(valid_loader)\n",
    "        \n",
    "        elapsed_time = get_timediff(start_time, time.time())\n",
    "        LOGGER.info(f' {epoch:02d}  | {lr_value:.8f}   {losses_mean:.3f}   {loss0_list_mean:.3f}   {loss1_list_mean:.3f} | {loss_valid:.3f}   {valid_map_score:.4f}   {valid_map_score*2/3:.4f}   {class_map[0]:.4f}  |  {elapsed_time} ')\n",
    "        \n",
    "        # 调度器迭代\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV3\"]:\n",
    "            scheduler_warmup.step()\n",
    "        elif CFG.scheduler in [\"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"]:\n",
    "            scheduler.step()\n",
    "\n",
    "        # 保存模型\n",
    "        # torch.save(op_model.state_dict(), f'{outputdir}/stage1_{CFG.suffix}_fold{n_fold}_{CFG.model_arch}_{CFG.image_size}_epoch{epoch}.pth')\n",
    "        \n",
    "        if valid_map_score > best_valid_map:\n",
    "            early_stop_num = 0\n",
    "            torch.save(op_model.state_dict(), f'{outputdir}/stage1_{CFG.suffix}_fold{n_fold}_{CFG.model_arch}_{CFG.image_size}_bestmap.pth')\n",
    "            best_valid_map = valid_map_score\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        elif early_stop_num >= CFG.max_early_stop:\n",
    "            LOGGER.info(\"\\nEarly Stop!\")\n",
    "            early_stop = True\n",
    "            os.rename(f'{outputdir}/stage1_{CFG.suffix}_fold{n_fold}_{CFG.model_arch}_{CFG.image_size}_bestmap.pth',\n",
    "                      f'{outputdir}/stage1_{CFG.suffix}_fold{n_fold}_{CFG.model_arch}_{CFG.image_size}_best_{best_epoch}_{int(round(best_valid_map,4)*10000)}.pth')\n",
    "            LOGGER.info(f\"best_valid_map: {best_valid_map}, best_epoch: {best_epoch}\\n\\n\\n\")\n",
    "            break\n",
    "\n",
    "\n",
    "    if not early_stop:        \n",
    "        os.rename(f'{outputdir}/stage1_{CFG.suffix}_fold{n_fold}_{CFG.model_arch}_{CFG.image_size}_bestmap.pth',\n",
    "                  f'{outputdir}/stage1_{CFG.suffix}_fold{n_fold}_{CFG.model_arch}_{CFG.image_size}_best_{best_epoch}_{int(round(best_valid_map,4)*10000)}.pth')\n",
    "        LOGGER.info(f\"best_valid_map: {best_valid_map}, best_epoch: {best_epoch}\\n\\n\\n\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
